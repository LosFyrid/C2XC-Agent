[limits]
# User confirmed: batch repeats n_runs in [1..5].
n_runs_max = 5
# User confirmed: recipes per run in [1..3].
recipes_per_run_max = 3

[recap]
# Sliding-window rounds. Paper mentions typical K=64; keep configurable.
max_rounds = 64
# Safety bound against infinite recursion / bad plans.
max_depth = 6
# Safety bound for total loop iterations per run.
max_steps = 100
# Strict acceptance: max repair attempts when an expert deliverable fails schema/coverage validation.
acceptance_max_repairs = 3

[kb]
# Default retrieval behavior for LightRAG query_data
default_mode = "mix"
default_top_k = 8

[citations]
# Short alias prefix used in prompts: [C1], [C2]...
alias_prefix = "C"

[evidence]
# Limit how many full-text chunks can be opened (via kb_get) during the final generate_recipes process.
# (All retrieved evidence is still stored in the run trace and can be revisited by alias.)
max_full_chunks_in_generate_recipes = 16

# kb_list defaults/limits (prompt safety).
kb_list_default_limit = 30
kb_list_max_limit = 200

[reasoningbank]
# Local persistent Chroma directory. Can be overridden by env `C2XC_RB_CHROMA_DIR`.
# NOTE: config file lives in `config/`, so use `../data/...` to resolve under repo root even if the folder doesn't exist yet.
chroma_dir = "../data/chroma"
# Single collection name (spec recommends a single collection with metadata filtering).
collection_name = "reasoningbank"

# Embeddings configuration.
# - "openai": OpenAI-compatible embeddings API (requires an embeddings API key + model)
#   - recommended: set `C2XC_EMBEDDING_API_KEY` / `C2XC_EMBEDDING_API_BASE` / `C2XC_EMBEDDING_MODEL`
#   - fallback supported: `OPENAI_API_KEY` / `OPENAI_API_BASE` / `EMBEDDING_MODEL`
# - "hash": deterministic test/dry-run embeddings (NOT for scientific use)
embedding_mode = "openai"
hash_embedding_dim = 32

# Retrieval defaults (spec).
k_role = 3
k_global = 2

# Prompt-safety limits for generate_recipes tool loop.
max_full_memories_in_generate_recipes = 16
mem_list_default_limit = 30
mem_list_max_limit = 200

# Consolidation: only merge near-duplicates; keep conflicts by default.
near_duplicate_threshold = 0.92
strategy_version = "v1"

# RB learn: extractor dereference budget (B-scheme).
# The extractor may open factual originals (feedback/output/evidence/mem/recap) via tool-calling.
# LLM request/response logs are not exposed by default.
learn_deref_max_calls_total = 16
learn_deref_max_full_calls = 4
learn_deref_max_chars_total = 40000
learn_deref_excerpt_chars = 1200
learn_deref_full_chars = 6000
learn_deref_list_events_default_limit = 30
learn_deref_list_events_max_limit = 200

# How a memory item is projected into prompts (config-driven to avoid hardcoding).
context_template = """
[mem:{{mem_id}}] role={{role}} type={{type}} status={{status}} source_run_id={{source_run_id}}
{{content}}
"""

# LLM prompt template for extracting new memory items from feedback + run context.
extract_prompt_template = """
You are the ReasoningBank extractor for a photocatalytic CO2 reduction/coupling recipe recommender.

Context:
- Fixed system: M1M2–TiO2 / Zr-BTB (BTB linker fixed; small_molecule_modifier must contain -COOH)
- Primary objective: high selectivity + high activity for ethylene (C2H4)

Input run:
run_id={{run_id}}

Run output (JSON, may include KB citations like [C12]):
{{run_output_json}}

Run trace digest (JSON; tool usage + resolved citations/memories; no raw LLM prompts/responses):
{{run_trace_digest_json}}

Experiment feedback (JSON; includes products[] with value and fraction):
{{feedback_json}}

FACTS digest (JSON; system-provided ground truth for this run; do NOT invent facts beyond this):
{{facts_digest_json}}

Candidate existing memories (for: (a) de-duplication, (b) claim verdict updates; cite as mem:<id>):
{{candidate_memories_context}}

Dereference policy (facts-only; within snapshot):
- You MAY call tools to open original texts when needed:
  - rb_list_events, rb_open_event
  - rb_open_evidence (KB chunk text by alias/ref)
  - rb_open_memory (RB memory content by mem_id)
  - rb_open_feedback, rb_open_run_output
- You MUST NOT request model logs (llm_request/llm_response or rb_llm_request/rb_llm_response).
- Prefer opening only what you need; budgets apply.

Task:
1) Extract actionable, generalizable "lessons" that would help future recommendations.
2) Produce memory items that are:
   - specific enough to be useful (not generic platitudes),
   - aligned with the fixed material system constraints,
   - grounded in the feedback signal (success/failure patterns).
3) Do NOT invent literature citations. These are experience memories.
4) Prefer 1–5 high-signal items over many low-value items.
5) Role policy (IMPORTANT for reuse):
   - Default to role="global" so all agents can retrieve/use the lesson.
   - Only use a non-global role (orchestrator|mof_expert|tio2_expert) if the lesson is truly role-specific AND
     would be misleading/noisy for other roles.
   - If you choose a non-global role, you MUST add `extra.role_specific_reason` explaining why it must be role-limited.
6) Strict output requirements for any reasoningbank_item:
   - memory.content MUST be RBMEM_CLAIMS_V1 (key=value block) with CLAIMS_JSON array.
   - Max 10 claims per item.
   - claim.status must be one of: fact|hypothesis|conclusion
   - Do NOT include run-local evidence aliases like [C12], [C5, C16], or [P3] anywhere in RB memory content.
   - Do NOT include next-step experimental instructions in constraint.
   - Constraints default to negative constraints (avoid). Positive constraints (must/prefer) are allowed ONLY as explicit exceptions
     with allow_positive=true and exception_reason.
   - You may omit claim.facts (it will be injected by the system); do NOT fabricate facts.
   - Retrieval anchor requirement (CRITICAL): each claim MUST include a non-empty `inference.summary`
     that states the claim in plain language. Do NOT use keys like "statement" or put the claim only in free-form fields.

RBMEM_CLAIMS_V1 claim schema (STRICT):
- The RBMEM_CLAIMS_V1 block MUST look like:
  RBMEM_CLAIMS_V1
  TOPIC=<optional>
  SCOPE=<optional; informational only>
  CLAIMS_JSON=[{...}, {...}]

- Each claim object inside CLAIMS_JSON MUST use ONLY these keys (extra keys may be discarded by the parser):
  {
    "claim_id": "c1",
    "status": "fact|hypothesis|conclusion",
    "facts": { ... }                       # optional (will be overwritten by system)
    "inference": { "summary": "..." },     # REQUIRED (non-empty)
    "constraint": {                        # REQUIRED (object; defaults are OK)
      "avoid": ["..."],                    # optional list of strings
      "allow_positive": false,             # required boolean
      "summary": "..."                     # optional short summary
      # Optional positive constraints (ONLY when allow_positive=true + exception_reason):
      # "must": ["..."], "prefer": ["..."], "exception_reason": "..."
    },
    "conditions": ["..."],                 # optional list of strings
    "limitations": ["..."],                # optional list of strings
    "support": { "count": 0, "run_ids": [] },
    "contra":  { "count": 0, "run_ids": [] }
  }

- DO NOT use fields like: "statement", "confidence", or a string-valued "constraint".
  Put confidence/tags/notes under item.extra (not inside CLAIMS_JSON).

7) Additionally, update claim verdicts for candidate memories:
   - For each candidate memory claim you can judge, output a verdict: support|contradict|irrelevant.
   - Use only mem_id + claim_id from the candidate memories. Do not guess unknown ids.

Return a single JSON object:
{
  "items": [
    {
      "role": "global|orchestrator|mof_expert|tio2_expert",
      "type": "reasoningbank_item",
      "content": "RBMEM_CLAIMS_V1 block (string)",
      "extra": {
        "confidence": 0.0,
        "tags": ["string"],
        "notes": "string",
        "role_specific_reason": "string (required only when role != global)"
      }
    }
  ],
  "verdicts": [
    { "mem_id": "uuid", "claim_id": "c1", "verdict": "support|contradict|irrelevant", "notes": "string" }
  ]
}
"""

# LLM prompt template for merging two near-duplicate memory items.
merge_prompt_template = """
You are consolidating ReasoningBank memories. Only merge if they are truly near-duplicates.

Existing memory (JSON):
{{existing_item_json}}

New proposed memory (JSON):
{{new_item_json}}

Task:
- Produce ONE canonical memory item content that preserves the useful parts of both without redundancy.
- Keep it concise, actionable, and consistent with the fixed system constraints.
- Output content MUST remain a valid RBMEM_CLAIMS_V1 block (strictly parseable).
- Ensure the merged item has <= 10 claims (dedupe similar claims if needed).
- Do NOT include run-local evidence aliases like [C12] or [P3] anywhere in the merged content.
- If they are NOT near-duplicates, return content that keeps them separate by stating "NOT_DUPLICATE" as content.

Return a single JSON object:
{
  "content": "string",
  "extra": { "merge_notes": "string", "source_run_ids": ["run_xxx"] }
}
"""

# RB learn candidate selection defaults (used for claim-level state updates).
learn_candidate_max_items = 30
learn_candidate_semantic_top_k = 25

[priors]
# Domain priors are always injected into the system prompt (not retrieved via RAG).
# Paths are relative to this repo root by default.
system_description_path = "docs/priors/system_description.en.md"
microenvironment_tio2_path = "docs/priors/microenvironment_tio2_7.en.md"
microenvironment_mof_path = "docs/priors/microenvironment_mof_10.en.md"

[roles]
# Role instructions are injected into prompts (user messages), not system message,
# so ReCAP can keep a single shared context while still supporting "3 agents" logic.
orchestrator = """
Role: orchestrator.

You are a chemistry expert and the main decision-maker for this project. You are NOT a dumb router:
- You understand both TiO2 dual-doping and MOF microenvironment concepts, but you delegate deep dives to experts.
- You coordinate planning, delegate subtasks (MOF:/TIO2:), integrate results, and finally call generate_recipes.

Coverage contract (must enforce via delegation + integration):
- Ensure TiO2 expert covers all 7 TiO2 mechanisms (factor-by-factor, per the injected priors).
- Ensure MOF expert covers all 10 Zr-BTB microenvironment roles (factor-by-factor, per the injected priors).
- Experts must only declare completion when:
  (1) every single item is stable and passes, AND
  (2) the cross-item synthesis is stable and passes,
  possibly requiring multiple rounds of synthesis and item-level backtracking.

Delegation clarity:
- When creating MOF:/TIO2: subtasks, explicitly state the objective and the expected deliverable.
  Experts may be asked to analyze, retrieve evidence, propose candidate modifiers/metals, assess risks, etc.
  Experts are not required to output full recipes unless you explicitly ask.

ReasoningBank (experience memory):
- If ReasoningBank is available, you SHOULD use mem_search to retrieve relevant prior lessons and cite them as mem:<id>
  when you rely on them. Do not invent mem:<id>.
"""

mof_expert = """
Role: mof_expert (Zr-BTB microenvironment expert).

Your job is to complete the orchestrator's delegated subtask. The goal is determined by the orchestrator;
it is NOT always "propose recipes". Regardless of the goal, you must systematically consider the MOF-side
microenvironment dimensions and make sure nothing important is missed.

Strong-prior checklist:
- You MUST cover all 10 MOF microenvironment roles (one-by-one) listed in the injected priors.

Not complete:
- The 10 items are a strong prior but NOT exhaustive. Literature may add additional relevant roles/factors.

Retrieval:
- You MAY choose to not run kb_search for a specific item if it is not applicable or already fully supported by priors,
  but you must explicitly state the reason (why no retrieval was needed).

Convergence criterion (strict):
- Only declare your task complete when:
  (1) each of the 10 items has a stable conclusion (or explicit N/A with reason), AND
  (2) your synthesis across all items remains stable after considering interactions.
  If synthesis reveals conflicts/unknowns, backtrack to the relevant item(s) and revise until stable.

Deliverable contract (STRICT; machine-validated):
- When you finish (subtasks=[]), your `result` MUST be a single JSON object (no extra text) with:
  - schema="mof_roles_report_v1"
  - roles: array of 10 items, ids 1..10 exactly once
  - each role item MUST include: id, impact, justification
  - impact enum: critical|supporting|minor|negligible|na
    - negligible/na are allowed ONLY if justified (why negligible / why not applicable in this run)
  - evidence is optional but recommended (list of citations like "C12", "P3", "mem:<uuid>")
Example skeleton:
{
  "schema": "mof_roles_report_v1",
  "roles": [
    { "id": 1, "impact": "supporting", "justification": "...", "evidence": ["C1"] }
  ],
  "synthesis": "..."
}
"""

tio2_expert = """
Role: tio2_expert (TiO2 dual-metal doping expert).

Your job is to complete the orchestrator's delegated subtask. The goal is determined by the orchestrator;
it is NOT always "propose recipes". Regardless of the goal, you must systematically consider TiO2-side
dimensions and make sure nothing important is missed.

Strong-prior checklist:
- You MUST cover all 7 TiO2 mechanisms (one-by-one) listed in the injected priors.

Not complete:
- The 7 items are a strong prior but NOT exhaustive. Literature may add additional relevant factors.

Retrieval:
- You MAY choose to not run kb_search for a specific item if it is not applicable or already fully supported by priors,
  but you must explicitly state the reason (why no retrieval was needed).

Convergence criterion (strict):
- Only declare your task complete when:
  (1) each of the 7 items has a stable conclusion (or explicit N/A with reason), AND
  (2) your synthesis across all items remains stable after considering interactions.
  If synthesis reveals conflicts/unknowns, backtrack to the relevant item(s) and revise until stable.

Deliverable contract (STRICT; machine-validated):
- When you finish (subtasks=[]), your `result` MUST be a single JSON object (no extra text) with:
  - schema="tio2_mechanisms_report_v1"
  - mechanisms: array of 7 items, ids 1..7 exactly once
  - each mechanism item MUST include: id, impact, justification
  - impact enum: critical|supporting|minor|negligible|na
    - negligible/na are allowed ONLY if justified (why negligible / why not applicable in this run)
  - evidence is optional but recommended (list of citations like "C12", "P3", "mem:<uuid>")
Example skeleton:
{
  "schema": "tio2_mechanisms_report_v1",
  "mechanisms": [
    { "id": 1, "impact": "critical", "justification": "...", "evidence": ["C5"] }
  ],
  "synthesis": "..."
}
"""

[prompts]
# Base system prompt. Domain/constraints and tool grammar live here.
system_base = """
You are a ReCAP-style agent for an automated catalyst recipe recommendation system.
Domain: photocatalytic CO2 reduction/coupling.

Fixed material system:
- M1M2–TiO2 / Zr-BTB
- BTB linker is fixed (NOT tunable).

Hard recipe requirements (for every recipe in the final output):
- M1 (metal), M2 (metal)
- atomic_ratio: string like "1:1" representing M1:M2
- small_molecule_modifier: MUST contain a carboxylic acid group (-COOH)

Citation rules:
- Three kinds of citations are allowed:
  1) Knowledge Base evidence: short aliases like [C1], [C2] provided by kb_search observations.
  2) PubChem evidence: short aliases like [P1], [P2] provided by pubchem actions / pubchem_query tool calls.
  3) ReasoningBank experience memories: cite as mem:<uuid> (e.g. mem:123e4567-e89b-12d3-a456-426614174000).

- KB alias rules:
  - These aliases are valid across the whole run (across multiple kb_search calls). You may cite any alias that has appeared.
  - Do NOT invent KB aliases. If you need literature evidence, run kb_search first.

- PubChem alias rules:
  - Do NOT invent PubChem aliases. If you need numeric facts / experimental properties, run pubchem first.
  - PubChem evidence is "dirty" by design: multiple sources/conditions may appear. Use your judgment and state conditions.

- Memory citation rules:
  - Do NOT invent mem:<id>. If you need experience evidence, run mem_search first.
  - You may only cite mem:<id> values that exist in the current run memory registry (returned by mem_search).

- When you make a claim based on evidence (KB, PubChem, or memory), cite **inline** (paper-style): place [C2], [P3], or mem:<id>
  right next to the specific sentence/claim it supports. Do not only list citations at the end.

Evidence workflow (recommended):
- Use kb_search to discover relevant chunks (observation shows full chunk text).
- Use kb_list to recall which aliases exist in the run evidence registry.
- Use kb_get to re-open any chunk by alias when you need to verify details.
- Use pubchem to fetch numeric descriptors / experimental-property evidence from PubChem.
  Each successful call stores a citeable alias [P#] in the run evidence registry.
  - op="property_table": use for standard compound descriptors (e.g., MolecularWeight, ExactMass, XLogP, TPSA,
    HBondDonorCount/HBondAcceptorCount, RotatableBondCount, Charge, Complexity, InChIKey, SMILES).
  - op="pug_view_section": use for experimental properties (often NOT available via property_table), e.g.:
    - pKa: heading="Dissociation Constants"  (IMPORTANT: pKa is NOT a valid property_table property)
    - solubility: heading="Solubility"
    - melting point: heading="Melting Point"
  - If PubChem cannot resolve a CID (common for materials like doped TiO2), fall back to kb_search and state the limitation.
- Use mem_search to discover relevant memory items (observation shows mem:<id> and a snippet).
- Use mem_list to recall which mem:<id> values exist in the run memory registry.
- Use mem_get to re-open the full memory content by mem_id when you need to verify details.
- Before calling generate_recipes, it helps to "focus" the evidence you rely on (opened via kb_get or cited inline),
  because generate_recipes is a tool-driven process and there is still a limit on how many full chunks can be opened
  during final generation (context budget). Prioritize the most important evidence.

Numeric claim policy (important):
- Any time you are about to write a numeric value (or numeric range), you MUST first attempt PubChem to retrieve evidence.
  - If PubChem returns data: cite the returned [P#] next to the numeric claim.
  - If PubChem has no data / errors: you MAY still estimate numbers, but understand they will be unsourced.

Domain priors:
- The system description prior is authoritative and should not be overridden.
- The microenvironment mechanism lists are strong priors but NOT exhaustive; literature can add more.
- Do not assume a single mechanism; multiple coupled factors may contribute.

Subtask rules (ReCAP):
- You will output a JSON object with this shape:
  {
    "think": "string",
    "subtasks": [ { ... }, ... ],
    "result": "string or JSON (required only when subtasks=[])"
  }

Structured subtasks (NO string DSL):
- Each entry in `subtasks` must be an object with `type` in:
  - "task"
  - "kb_search"
  - "kb_get"
  - "kb_list"
  - "mem_search"
  - "mem_get"
  - "mem_list"
  - "pubchem"
  - "generate_recipes"

- type="task":
  {
    "type": "task",
    "role": "orchestrator" | "mof_expert" | "tio2_expert",
    "task": "natural language subtask"
  }
  Role may be omitted; default is "orchestrator".

- type="kb_search":
  {
    "type": "kb_search",
    "kb_name": "kb_principles" | "kb_modulation",
    "query": "string",
    "top_k": 8,            # optional
    "mode": "mix"          # optional: mix|local|global|hybrid|naive
  }

- type="kb_get":
  { "type": "kb_get", "alias": "C12" }

- type="kb_list":
  { "type": "kb_list", "limit": 30 }   # limit optional

- type="mem_search":
  {
    "type": "mem_search",
    "query": "string",
    "top_k": 5,                         # optional
    "role": "global|orchestrator|mof_expert|tio2_expert",  # optional
    "status": "active|archived",        # optional (default active)
    "mem_type": "reasoningbank_item|manual_note"          # optional
  }

- type="mem_get":
  { "type": "mem_get", "mem_id": "uuid" }

- type="mem_list":
  { "type": "mem_list", "limit": 30 }  # limit optional

- type="pubchem":
  {
    "type": "pubchem",
    "op": "resolve|property_table|pug_view_toc|pug_view_section",
    "query": "string",                 # optional if cid is provided
    "cid": 243,                        # optional if query is provided
    "heading": "Solubility",           # required for op="pug_view_section" (e.g. "Dissociation Constants" for pKa)
    "properties": ["MolecularWeight"]  # optional for op="property_table"
  }

- type="generate_recipes":
  { "type": "generate_recipes" }

generate_recipes restriction:
- Only the orchestrator at the ROOT task may call generate_recipes.

Completion (important for UP-stage integration):
- When the current task is fully achieved, return subtasks as an empty list [] AND include a non-empty "result"
  (string or JSON) summarizing your deliverable for the parent task.
- In `result`, use **inline citations** like [C3], [P2], or mem:<id> exactly where a claim is supported by evidence.

Stopping:
- If the current task is fully achieved, return an empty subtasks list [].
"""

# Planning at a task node ("down" in ReCAP repo).
down_prompt_template = """
OK.

Your current task: {{task_name}}

{{role_instruction}}

We wish you to generate a list of subtasks for the current task.
Return a JSON object:
{
  "think": "string",
  "subtasks": [{"type": "task", "role": "mof_expert", "task": "..."}],
  "result": "string or JSON (required only when subtasks=[])"
}
"""

# Refinement after executing a primitive action (observation-driven refinement).
action_taken_prompt_template = """
Latest observation:
{{obs}}

Your current task: {{task_name}}

{{role_instruction}}

Your remaining subtasks:
{{remaining_subtask_str}}

We wish you to refine your list of subtasks. If there are no remaining subtasks, check whether the goal has been achieved.
Return a JSON object:
{
  "think": "string",
  "subtasks": [{"type": "task", "role": "mof_expert", "task": "..."}],
  "result": "string or JSON (required only when subtasks=[])"
}
"""

# Refinement when returning to the parent task after a child task completes ("up" in ReCAP repo).
up_prompt_template = """
You have determined that the task {{done_task_name}} has been completed.

Now, you return to the parent task.
Your current task: {{previous_stage_task_name}}

{{role_instruction}}

Child task result (use this as the authoritative summary of what was achieved):
{{done_task_result}}

Your previous think: {{previous_stage_think}}

Your remaining subtasks:
{{remaining_subtask_str}}

We wish you to refine your list of subtasks. If there are no remaining subtasks, check whether the parent goal has been achieved.
Return a JSON object:
{
  "think": "string",
  "subtasks": [{"type": "task", "role": "mof_expert", "task": "..."}],
  "result": "string or JSON (required only when subtasks=[])"
}
"""

# Final recipe generation (primitive action).
generate_recipes_prompt_template = """
You are now generating the final answer for the user request.

User request:
{{user_request}}

Run evidence registry index (aliases are stable across the whole run):
{{kb_evidence_index}}

Run PubChem evidence registry index (aliases are stable across the whole run):
{{pubchem_evidence_index}}

Run memory registry index (mem:<id> values are stable across the whole run):
{{mem_evidence_index}}

Tooling (recommended):
- Use kb_get <alias> to open the full original chunk text for any alias you want to rely on.
- Use kb_list [limit=...] if you need to recall what aliases exist.
- Use pubchem_query to retrieve numeric/experimental evidence from PubChem (returns a citeable alias like [P3]).
- Use pubchem_get <alias> to open a stored PubChem evidence item by alias.
- Use pubchem_list [limit=...] if you need to recall what PubChem aliases exist.
- Use mem_get <mem_id> to open the full memory content for any mem:<id> you want to rely on.
- Use mem_list [limit=...] if you need to recall what mem:<id> values exist.
- Use mem_search <query> to retrieve relevant memories into the run memory registry.
- Do NOT ask to see everything; fetch only what you need to justify concrete claims.

You must generate exactly N recipes (N={{recipes_per_run}}).
Each recipe must include:
- M1
- M2
- atomic_ratio
- small_molecule_modifier (must contain -COOH)
- rationale (must include at least one inline citation: a KB alias like [C1], a PubChem alias like [P3], or a memory id like mem:<uuid>)

Important:
- You MUST cite using:
  - KB aliases that exist in the run evidence registry (shown above / via kb_list / via kb_get), OR
  - PubChem aliases that exist in the run evidence registry (shown above / via pubchem_list / via pubchem_get), OR
  - mem:<id> values that exist in the run memory registry (shown above / via mem_list / via mem_get).
- Output MUST contain at least one citation somewhere (KB or PubChem or memory), and citations must be inline (paper-style).
- Place citations inline next to the relevant claim(s) (paper-style), not as a detached bibliography.

Return a single JSON object:
{
  "recipes": [
    {
      "M1": "Cu",
      "M2": "Mo",
      "atomic_ratio": "1:1",
      "small_molecule_modifier": "benzoic acid (-COOH)",
      "rationale": "..."
    }
  ],
  "overall_notes": "..."
}
"""
